{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsun/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras import optimizers\n",
    "import keras.layers.advanced_activations\n",
    "import scipy\n",
    "import random\n",
    "import matplotlib.pyplot as plt  \n",
    "from scipy.stats import norm  \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import VarianceScaling,RandomNormal\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, concatenate\n",
    "from keras.layers import UpSampling2D, Reshape, Lambda, Flatten, Activation,Concatenate,Add\n",
    "from keras.models import Model  \n",
    "from keras.optimizers import SGD, Adadelta, Adagrad,Adam\n",
    "from keras import backend as K  \n",
    "from keras import objectives  \n",
    "from keras.utils.vis_utils import plot_model  \n",
    "from keras.utils import np_utils, generic_utils\n",
    "import sys \n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'\n",
    "import sklearn\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "%matplotlib inline\n",
    "from sklearn import manifold, datasets,cluster\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = np.load(\"../train_img_aug.npy\").reshape([-1,256,256,1])\n",
    "train_seg = np.load(\"../train_seg_aug.npy\").reshape([-1,256,256,1])\n",
    "train_flo = np.load(\"../train_flo_aug.npy\")\n",
    "train_rflo = np.load(\"../train_rflo_aug.npy\")\n",
    "#train_img = np.log(train_img+1.0)\n",
    "train_seg = np_utils.to_categorical(train_seg, 2)\n",
    "\n",
    "test_img = np.load(\"../test_img.npy\").reshape([-1,256,256,1])\n",
    "test_seg = np.load(\"../test_seg.npy\").reshape([-1,256,256,1])\n",
    "test_flo = np.load(\"../test_flo.npy\")\n",
    "test_rflo = np.load(\"../test_rflo.npy\")\n",
    "test_seg = np_utils.to_categorical(test_seg, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsun/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:57: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"co...)`\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 256, 256\n",
    "img_channels = 1\n",
    "\n",
    "batch_size =50\n",
    "latent_dim = 256\n",
    "nb_epoch = 50\n",
    "intermediate_dim =256\n",
    "original_dim = img_rows*img_cols\n",
    "LRelu = 'relu'\n",
    "\n",
    "#USE = 'autoencoder'\n",
    "#USE = 'vae'\n",
    "#encoder:\n",
    "input_img = Input(shape=(img_rows, img_cols,img_channels))\n",
    "input_flo = Input(shape=(img_rows, img_cols,3))\n",
    "input_rflo = Input(shape=(img_rows, img_cols,3))\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',dilation_rate = 2)(input_img)\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',dilation_rate = 2)(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',dilation_rate = 2)(pool1)\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',dilation_rate = 2)(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',dilation_rate = 2)(pool2)\n",
    "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',dilation_rate = 2)(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = Dropout(0.5)(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "merge6 = Concatenate()([drop4,up6])\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "merge7 = Concatenate()([conv3,up7])\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "merge8 =Concatenate()([conv2,up8])\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "merge9 = Concatenate()([conv1,up9,input_flo,input_rflo])\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv10 = Conv2D(2, 1, activation = 'softmax')(conv9)\n",
    "\n",
    "unet = Model(input = [input_img,input_flo,input_rflo], output = conv10)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "#early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=0, mode='auto')\n",
    "csv_logger = CSVLogger('Unet_dilation222222_flo_last.csv')\n",
    "\n",
    "#decoded = Conv2D(2, (3, 3), activation='softmax', padding='same')(upsample_10)\n",
    "#decoded = Flatten()(decoded)\n",
    "#decoded = Dense(256*256,activation='softmax')(decoded)\n",
    "\n",
    "\n",
    "EarlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=0, mode='auto')\n",
    "checkpoint = ModelCheckpoint('Unet_dilation222222_flo_last.h5',monitor ='val_loss',verbose = 1,save_best_only = True)\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true[:,:,:,1]) \n",
    "    y_pred_f = K.flatten(y_pred[:,:,:,1]) \n",
    "    intersection = K.sum(y_true_f * y_pred_f) \n",
    "    return (2. * intersection + 1e-6) / (K.sum(K.square(y_true_f)) + K.sum(K.square(y_pred_f)) + 1e-6)\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "#def ae_loss(x, decoded):  \n",
    "#    xent_loss = original_dim * objectives.mean_squared_error(x,decoded)\n",
    "#    return xent_loss\n",
    "adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "#autoencoder = Model(inputs=input_img, outputs=decoded)\n",
    "unet.compile(optimizer=adam, loss=dice_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13800 samples, validate on 127 samples\n",
      "Epoch 1/200\n",
      "13800/13800 [==============================] - 974s 71ms/step - loss: -0.5066 - val_loss: -0.5311\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.53107, saving model to Unet_dilation222222_flo_last.h5\n",
      "Epoch 2/200\n",
      "13800/13800 [==============================] - 950s 69ms/step - loss: -0.6720 - val_loss: -0.6886\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.53107 to -0.68863, saving model to Unet_dilation222222_flo_last.h5\n",
      "Epoch 3/200\n",
      "13800/13800 [==============================] - 949s 69ms/step - loss: -0.7916 - val_loss: -0.7317\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.68863 to -0.73167, saving model to Unet_dilation222222_flo_last.h5\n",
      "Epoch 4/200\n",
      "13800/13800 [==============================] - 950s 69ms/step - loss: -0.8384 - val_loss: -0.7496\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.73167 to -0.74960, saving model to Unet_dilation222222_flo_last.h5\n",
      "Epoch 5/200\n",
      "13800/13800 [==============================] - 950s 69ms/step - loss: -0.8679 - val_loss: -0.7669\n",
      "\n",
      "Epoch 00005: val_loss improved from -0.74960 to -0.76691, saving model to Unet_dilation222222_flo_last.h5\n",
      "Epoch 6/200\n",
      "13800/13800 [==============================] - 950s 69ms/step - loss: -0.8902 - val_loss: -0.7289\n",
      "\n",
      "Epoch 00006: val_loss did not improve from -0.76691\n",
      "Epoch 7/200\n",
      "13800/13800 [==============================] - 948s 69ms/step - loss: -0.8839 - val_loss: -0.7610\n",
      "\n",
      "Epoch 00007: val_loss did not improve from -0.76691\n",
      "Epoch 8/200\n",
      "13800/13800 [==============================] - 949s 69ms/step - loss: -0.9696 - val_loss: -0.8113\n",
      "\n",
      "Epoch 00008: val_loss improved from -0.76691 to -0.81131, saving model to Unet_dilation222222_flo_last.h5\n",
      "Epoch 9/200\n",
      "13800/13800 [==============================] - 949s 69ms/step - loss: -0.9765 - val_loss: -0.8134\n",
      "\n",
      "Epoch 00009: val_loss improved from -0.81131 to -0.81344, saving model to Unet_dilation222222_flo_last.h5\n",
      "Epoch 10/200\n",
      "13800/13800 [==============================] - 949s 69ms/step - loss: -0.9732 - val_loss: -0.8183\n",
      "\n",
      "Epoch 00010: val_loss improved from -0.81344 to -0.81825, saving model to Unet_dilation222222_flo_last.h5\n",
      "Epoch 11/200\n",
      "13800/13800 [==============================] - 950s 69ms/step - loss: -0.9794 - val_loss: -0.8088\n",
      "\n",
      "Epoch 00011: val_loss did not improve from -0.81825\n",
      "Epoch 12/200\n",
      "13800/13800 [==============================] - 949s 69ms/step - loss: -0.9832 - val_loss: -0.8094\n",
      "\n",
      "Epoch 00012: val_loss did not improve from -0.81825\n",
      "Epoch 13/200\n",
      "13800/13800 [==============================] - 949s 69ms/step - loss: -0.9835 - val_loss: -0.8051\n",
      "\n",
      "Epoch 00013: val_loss did not improve from -0.81825\n",
      "Epoch 14/200\n",
      "13800/13800 [==============================] - 950s 69ms/step - loss: -0.9853 - val_loss: -0.8122\n",
      "\n",
      "Epoch 00014: val_loss did not improve from -0.81825\n",
      "Epoch 15/200\n",
      "13800/13800 [==============================] - 947s 69ms/step - loss: -0.9707 - val_loss: -0.7995\n",
      "\n",
      "Epoch 00015: val_loss did not improve from -0.81825\n",
      "Epoch 16/200\n",
      "13800/13800 [==============================] - 947s 69ms/step - loss: -0.9885 - val_loss: -0.8002\n",
      "\n",
      "Epoch 00016: val_loss did not improve from -0.81825\n",
      "Epoch 17/200\n",
      "13800/13800 [==============================] - 945s 68ms/step - loss: -0.9899 - val_loss: -0.7991\n",
      "\n",
      "Epoch 00017: val_loss did not improve from -0.81825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fca39a74390>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.fit([train_img,train_flo,train_rflo], train_seg,\n",
    "        shuffle=True,\n",
    "        epochs=200,\n",
    "        batch_size=20,\n",
    "        validation_data=([test_img,test_flo,test_rflo],test_seg),callbacks=[EarlyStopping,checkpoint,lr_reducer,csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
