{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsun/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras import optimizers\n",
    "import keras.layers.advanced_activations\n",
    "import scipy\n",
    "import random\n",
    "import matplotlib.pyplot as plt  \n",
    "from scipy.stats import norm  \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.initializers import VarianceScaling,RandomNormal\n",
    "from keras.layers import Input, Dense, Dropout, Conv2D, MaxPooling2D, concatenate\n",
    "from keras.layers import UpSampling2D, Reshape, Lambda, Flatten, Activation,Concatenate,Add\n",
    "from keras.models import Model  \n",
    "from keras.optimizers import SGD, Adadelta, Adagrad,Adam\n",
    "from keras import backend as K  \n",
    "from keras import objectives  \n",
    "from keras.utils.vis_utils import plot_model  \n",
    "from keras.utils import np_utils, generic_utils\n",
    "import sys \n",
    "import tensorflow as tf\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "import sklearn\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.ticker import NullFormatter\n",
    "%matplotlib inline\n",
    "from sklearn import manifold, datasets,cluster\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = np.load(\"../train_img_aug.npy\").reshape([-1,256,256,1])\n",
    "train_seg = np.load(\"../train_seg_aug.npy\").reshape([-1,256,256,1])\n",
    "train_flo = np.load(\"../train_flo_aug.npy\")\n",
    "train_rflo = np.load(\"../train_rflo_aug.npy\")\n",
    "#train_img = np.log(train_img+1.0)\n",
    "train_seg = np_utils.to_categorical(train_seg, 2)\n",
    "\n",
    "test_img = np.load(\"../test_img.npy\").reshape([-1,256,256,1])\n",
    "test_seg = np.load(\"../test_seg.npy\").reshape([-1,256,256,1])\n",
    "test_flo = np.load(\"../test_flo.npy\")\n",
    "test_rflo = np.load(\"../test_rflo.npy\")\n",
    "test_seg = np_utils.to_categorical(test_seg, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsun/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:75: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"co...)`\n"
     ]
    }
   ],
   "source": [
    "img_rows, img_cols = 256, 256\n",
    "img_channels = 1\n",
    "\n",
    "batch_size =50\n",
    "latent_dim = 256\n",
    "nb_epoch = 50\n",
    "intermediate_dim =256\n",
    "original_dim = img_rows*img_cols\n",
    "LRelu = 'relu'\n",
    "\n",
    "#USE = 'autoencoder'\n",
    "#USE = 'vae'\n",
    "#encoder:\n",
    "input_img = Input(shape=(img_rows, img_cols,img_channels))\n",
    "input_flo = Input(shape=(img_rows, img_cols,3))\n",
    "input_rflo = Input(shape=(img_rows, img_cols,3))\n",
    "\n",
    "concate_flo = Concatenate()([input_flo,input_rflo])\n",
    "conv_flo_1 = Conv2D(20, (3, 3), padding='same',kernel_initializer='normal',dilation_rate=2)(concate_flo)\n",
    "conv_flo_1 = Activation('relu')(conv_flo_1)\n",
    "conv_flo_1 = BatchNormalization()(conv_flo_1)\n",
    "#maxpool_flo_1 = MaxPooling2D((2, 2),padding='same')(conv_flo_1)\n",
    "conv_flo_2 = Conv2D(20, (3, 3), padding='same',kernel_initializer='normal',dilation_rate=2)(conv_flo_1)\n",
    "conv_flo_2 = Activation('relu')(conv_flo_2)\n",
    "conv_flo_2 = BatchNormalization()(conv_flo_2)\n",
    "#maxpool_flo_2 = MaxPooling2D((2, 2),  padding='same')(conv_flo_2)\n",
    "conv_flo_3 = Conv2D(20, (3, 3),padding='same',kernel_initializer='normal',dilation_rate=1)(conv_flo_2)\n",
    "conv_flo_3 = Activation(LRelu)(conv_flo_3)\n",
    "conv_flo_3 = BatchNormalization()(conv_flo_3)\n",
    "\n",
    "\n",
    "\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',dilation_rate = 2)(input_img)\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',dilation_rate = 2)(conv1)\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',dilation_rate = 2)(pool1)\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',dilation_rate = 2)(conv2)\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',dilation_rate = 2)(pool2)\n",
    "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal',dilation_rate = 2)(conv3)\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = Dropout(0.5)(conv4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "#drop5 = Concatenate()([maxpool_flo_4,drop5])\n",
    "\n",
    "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "merge6 = Concatenate()([drop4,up6])\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "merge7 = Concatenate()([conv3,up7])\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "merge8 =Concatenate()([conv2,up8])\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "merge9 = Concatenate()([conv1,up9,conv_flo_3])\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "conv10 = Conv2D(2, 1, activation = 'softmax')(conv9)\n",
    "\n",
    "unet = Model(input = [input_img,input_flo,input_rflo], output = conv10)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1), cooldown=0, patience=5, min_lr=0.5e-6)\n",
    "#early_stopper = EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=0, mode='auto')\n",
    "csv_logger = CSVLogger('Unet_dilation222222_flo_convlast.csv')\n",
    "\n",
    "\n",
    "\n",
    "#decoded = Conv2D(2, (3, 3), activation='softmax', padding='same')(upsample_10)\n",
    "#decoded = Flatten()(decoded)\n",
    "#decoded = Dense(256*256,activation='softmax')(decoded)\n",
    "\n",
    "\n",
    "EarlyStopping = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=0, mode='auto')\n",
    "checkpoint = ModelCheckpoint('AUG_dilation222222_flo_convlast.h5',monitor ='val_loss',verbose = 1,save_best_only = True)\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true[:,:,:,1]) \n",
    "    y_pred_f = K.flatten(y_pred[:,:,:,1]) \n",
    "    intersection = K.sum(y_true_f * y_pred_f) \n",
    "    return (2. * intersection + 1e-6) / (K.sum(K.square(y_true_f)) + K.sum(K.square(y_pred_f)) + 1e-6)\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "#def ae_loss(x, decoded):  \n",
    "#    xent_loss = original_dim * objectives.mean_squared_error(x,decoded)\n",
    "#    return xent_loss\n",
    "adam = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "#autoencoder = Model(inputs=input_img, outputs=decoded)\n",
    "unet.compile(optimizer=adam, loss=dice_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13800 samples, validate on 127 samples\n",
      "Epoch 1/200\n",
      "13800/13800 [==============================] - 1082s 78ms/step - loss: -0.5447 - val_loss: -0.5523\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to -0.55231, saving model to AUG_dilation222222_flo_convlast.h5\n",
      "Epoch 2/200\n",
      "13800/13800 [==============================] - 1074s 78ms/step - loss: -0.6925 - val_loss: -0.6478\n",
      "\n",
      "Epoch 00002: val_loss improved from -0.55231 to -0.64779, saving model to AUG_dilation222222_flo_convlast.h5\n",
      "Epoch 3/200\n",
      "13800/13800 [==============================] - 1075s 78ms/step - loss: -0.7926 - val_loss: -0.7223\n",
      "\n",
      "Epoch 00003: val_loss improved from -0.64779 to -0.72230, saving model to AUG_dilation222222_flo_convlast.h5\n",
      "Epoch 4/200\n",
      "13800/13800 [==============================] - 1077s 78ms/step - loss: -0.8395 - val_loss: -0.7573\n",
      "\n",
      "Epoch 00004: val_loss improved from -0.72230 to -0.75735, saving model to AUG_dilation222222_flo_convlast.h5\n",
      "Epoch 5/200\n",
      "13800/13800 [==============================] - 1078s 78ms/step - loss: -0.8730 - val_loss: -0.7674\n",
      "\n",
      "Epoch 00005: val_loss improved from -0.75735 to -0.76736, saving model to AUG_dilation222222_flo_convlast.h5\n",
      "Epoch 6/200\n",
      "13800/13800 [==============================] - 1076s 78ms/step - loss: -0.8907 - val_loss: -0.7656\n",
      "\n",
      "Epoch 00006: val_loss did not improve from -0.76736\n",
      "Epoch 7/200\n",
      "13800/13800 [==============================] - 1075s 78ms/step - loss: -0.9106 - val_loss: -0.7780\n",
      "\n",
      "Epoch 00007: val_loss improved from -0.76736 to -0.77800, saving model to AUG_dilation222222_flo_convlast.h5\n",
      "Epoch 8/200\n",
      "13800/13800 [==============================] - 1073s 78ms/step - loss: -0.9095 - val_loss: -0.7712\n",
      "\n",
      "Epoch 00008: val_loss did not improve from -0.77800\n",
      "Epoch 9/200\n",
      "13800/13800 [==============================] - 1073s 78ms/step - loss: -0.9320 - val_loss: -0.7845\n",
      "\n",
      "Epoch 00009: val_loss improved from -0.77800 to -0.78448, saving model to AUG_dilation222222_flo_convlast.h5\n",
      "Epoch 10/200\n",
      "13800/13800 [==============================] - 1074s 78ms/step - loss: -0.9436 - val_loss: -0.7871\n",
      "\n",
      "Epoch 00010: val_loss improved from -0.78448 to -0.78710, saving model to AUG_dilation222222_flo_convlast.h5\n",
      "Epoch 11/200\n",
      "13800/13800 [==============================] - 1072s 78ms/step - loss: -0.9509 - val_loss: -0.7879\n",
      "\n",
      "Epoch 00011: val_loss improved from -0.78710 to -0.78791, saving model to AUG_dilation222222_flo_convlast.h5\n",
      "Epoch 12/200\n",
      "13800/13800 [==============================] - 1072s 78ms/step - loss: -0.9500 - val_loss: -0.7523\n",
      "\n",
      "Epoch 00012: val_loss did not improve from -0.78791\n",
      "Epoch 13/200\n",
      "13800/13800 [==============================] - 1068s 77ms/step - loss: -0.9577 - val_loss: -0.8006\n",
      "\n",
      "Epoch 00013: val_loss improved from -0.78791 to -0.80064, saving model to AUG_dilation222222_flo_convlast.h5\n",
      "Epoch 14/200\n",
      "13800/13800 [==============================] - 1068s 77ms/step - loss: -0.9681 - val_loss: -0.7985\n",
      "\n",
      "Epoch 00014: val_loss did not improve from -0.80064\n",
      "Epoch 15/200\n",
      "13800/13800 [==============================] - 1051s 76ms/step - loss: -0.9719 - val_loss: -0.8033\n",
      "\n",
      "Epoch 00015: val_loss improved from -0.80064 to -0.80330, saving model to AUG_dilation222222_flo_convlast.h5\n",
      "Epoch 16/200\n",
      "13800/13800 [==============================] - 1035s 75ms/step - loss: -0.9750 - val_loss: -0.8056\n",
      "\n",
      "Epoch 00016: val_loss improved from -0.80330 to -0.80556, saving model to AUG_dilation222222_flo_convlast.h5\n",
      "Epoch 17/200\n",
      "13800/13800 [==============================] - 1022s 74ms/step - loss: -0.9775 - val_loss: -0.8171\n",
      "\n",
      "Epoch 00017: val_loss improved from -0.80556 to -0.81705, saving model to AUG_dilation222222_flo_convlast.h5\n",
      "Epoch 18/200\n",
      "13800/13800 [==============================] - 1012s 73ms/step - loss: -0.9800 - val_loss: -0.8084\n",
      "\n",
      "Epoch 00018: val_loss did not improve from -0.81705\n",
      "Epoch 19/200\n",
      "13800/13800 [==============================] - 1035s 75ms/step - loss: -0.9688 - val_loss: -0.7950\n",
      "\n",
      "Epoch 00019: val_loss did not improve from -0.81705\n",
      "Epoch 20/200\n",
      "13800/13800 [==============================] - 1029s 75ms/step - loss: -0.9843 - val_loss: -0.8019\n",
      "\n",
      "Epoch 00020: val_loss did not improve from -0.81705\n",
      "Epoch 21/200\n",
      "13800/13800 [==============================] - 1018s 74ms/step - loss: -0.9863 - val_loss: -0.8130\n",
      "\n",
      "Epoch 00021: val_loss did not improve from -0.81705\n",
      "Epoch 22/200\n",
      "13800/13800 [==============================] - 1037s 75ms/step - loss: -0.9873 - val_loss: -0.8067\n",
      "\n",
      "Epoch 00022: val_loss did not improve from -0.81705\n",
      "Epoch 23/200\n",
      "13800/13800 [==============================] - 1021s 74ms/step - loss: -0.9897 - val_loss: -0.8077\n",
      "\n",
      "Epoch 00023: val_loss did not improve from -0.81705\n",
      "Epoch 24/200\n",
      "13800/13800 [==============================] - 1031s 75ms/step - loss: -0.9906 - val_loss: -0.8063\n",
      "\n",
      "Epoch 00024: val_loss did not improve from -0.81705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f32d0165f60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.fit([train_img,train_flo,train_rflo], train_seg,\n",
    "        shuffle=True,\n",
    "        epochs=200,\n",
    "        batch_size=20,\n",
    "        validation_data=([test_img,test_flo,test_rflo],test_seg),callbacks=[EarlyStopping,checkpoint,lr_reducer,csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
